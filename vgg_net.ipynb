{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote, urlparse\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "CHUNK_SIZE = 40960\n",
    "DATA_SOURCE_MAPPING = 'crop-diseases-classification:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4561002%2F7791706%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240520%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240520T134132Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D39d8dad0ba6825e394ad9af48d6e950381ac9ed7b2a6680cdc6129d03fe2532a0018bd8d84b49aee5dced46d84b32aa1b3ea9162870cf4a268d0ce590d2d66602b2966f0d4882d9435621be322902b0a0f6cd225c67c731f35787a99c06149f67b186fec901f68ed602233b4c1bf4337bdb2f1ac824f9e5d3ef40f0c4a4f955ed70b1799f3879917953e9084ba354da748447ced4d3cd3527ca0bdcd5e93ec2e5adededa5dc9a01b1ca3cc67a7ae3d534fcefd2c09e3d9664a6b8a10f829df7cee14b7d5ff3b38db1ea4089677dce834ed8762926a9002aad923965aaec2c548315a98f1090267389ff5eb80a90cb513ed1bf0ef36fb0d78f923abf2fe2c428e'\n",
    "\n",
    "KAGGLE_INPUT_PATH='/kaggle/input'\n",
    "KAGGLE_WORKING_PATH='/kaggle/working'\n",
    "KAGGLE_SYMLINK='kaggle'\n",
    "\n",
    "!umount /kaggle/input/ 2> /dev/null\n",
    "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
    "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
    "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
    "\n",
    "try:\n",
    "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "try:\n",
    "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "\n",
    "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
    "    directory, download_url_encoded = data_source_mapping.split(':')\n",
    "    download_url = unquote(download_url_encoded)\n",
    "    filename = urlparse(download_url).path\n",
    "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
    "    try:\n",
    "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
    "            total_length = fileres.headers['content-length']\n",
    "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
    "            dl = 0\n",
    "            data = fileres.read(CHUNK_SIZE)\n",
    "            while len(data) > 0:\n",
    "                dl += len(data)\n",
    "                tfile.write(data)\n",
    "                done = int(50 * dl / int(total_length))\n",
    "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
    "                sys.stdout.flush()\n",
    "                data = fileres.read(CHUNK_SIZE)\n",
    "            if filename.endswith('.zip'):\n",
    "              with ZipFile(tfile) as zfile:\n",
    "                zfile.extractall(destination_path)\n",
    "            else:\n",
    "              with tarfile.open(tfile.name) as tarfile:\n",
    "                tarfile.extractall(destination_path)\n",
    "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
    "    except HTTPError as e:\n",
    "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
    "        continue\n",
    "    except OSError as e:\n",
    "        print(f'Failed to load {download_url} to path {destination_path}')\n",
    "        continue\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/crop-diseases-classification/Data/train.csv\")\n",
    "\n",
    "with open(\"/kaggle/input/crop-diseases-classification/Data/label_num_to_disease_map.json\", \"r\") as file:\n",
    "    label_name = json.load(file)\n",
    "\n",
    "image_path = \"/kaggle/input/crop-diseases-classification/Data/train_images\"\n",
    "df[\"image_path\"] = df[\"image_id\"].apply(lambda x: os.path.join(image_path, x))\n",
    "df[\"label_name\"] = df[\"label\"].apply(lambda x: label_name[str(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label_name',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label_name',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_name), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(train_generator)\n",
    "train_pred_labels = np.argmax(train_predictions, axis=1)\n",
    "train_true_labels = train_generator.classes\n",
    "\n",
    "val_predictions = model.predict(val_generator)\n",
    "val_pred_labels = np.argmax(val_predictions, axis=1)\n",
    "val_true_labels = val_generator.classes\n",
    "\n",
    "train_accuracy = accuracy_score(train_true_labels, train_pred_labels)\n",
    "train_precision = precision_score(train_true_labels, train_pred_labels, average='macro')\n",
    "train_recall = recall_score(train_true_labels, train_pred_labels, average='macro')\n",
    "train_f1_score = f1_score(train_true_labels, train_pred_labels, average='macro')\n",
    "\n",
    "val_accuracy = accuracy_score(val_true_labels, val_pred_labels)\n",
    "val_precision = precision_score(val_true_labels, val_pred_labels, average='macro')\n",
    "val_recall = recall_score(val_true_labels, val_pred_labels, average='macro')\n",
    "val_f1_score = f1_score(val_true_labels, val_pred_labels, average='macro')\n",
    "\n",
    "performance_table = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Training Set': [train_accuracy, train_precision, train_recall, train_f1_score],\n",
    "    'Validation Set': [val_accuracy, val_precision, val_recall, val_f1_score]\n",
    "})\n",
    "\n",
    "print(performance_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
